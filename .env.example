# Open Router API Configuration
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_api_key_here

# Default model to use (can be overridden via CLI)
# Options:
#   - google/gemini-flash-1.5 (free tier, fast, good for development)
#   - anthropic/claude-3.5-sonnet (best reasoning, pay-as-you-go)
#   - meta-llama/llama-3.1-8b-instruct (very cheap)
#   - openai/gpt-4o-mini (cheap, fast)
DEFAULT_MODEL=google/gemini-flash-1.5

# Your app name (shows in Open Router dashboard for usage tracking)
APP_NAME=helios

# Optional: Site URL (for Open Router analytics)
SITE_URL=https://github.com/yourusername/helios

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Maximum tokens for responses
MAX_TOKENS=2048

# Temperature for model responses (0.0-2.0)
# Lower = more focused, Higher = more creative
TEMPERATURE=0.7
